import os
import base64
from io import BytesIO
from PIL import Image
import streamlit as st
from openai import OpenAI

# -------------------- C·∫•u h√¨nh trang --------------------
st.set_page_config(page_title="Chat with OpenAI", page_icon="üí¨", layout="centered")

# -------------------- API key --------------------
api_key = st.secrets.get("OPENAI_API_KEY", None) or os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("Ch∆∞a c√≥ OPENAI_API_KEY. V√†o Settings ‚Üí Secrets c·ªßa Streamlit Cloud ƒë·ªÉ th√™m.")
    st.stop()
client = OpenAI(api_key=api_key)

# -------------------- Ti·ªán √≠ch ·∫£nh --------------------
def _img_to_b64(img: Image.Image, fmt="PNG") -> str:
    buf = BytesIO(); img.save(buf, format=fmt)
    return base64.b64encode(buf.getvalue()).decode("utf-8")

def _file_to_b64(upload) -> str:
    if upload is None: return None
    return base64.b64encode(upload.getvalue()).decode("utf-8")

def _b64_to_img(b64: str) -> Image.Image:
    return Image.open(BytesIO(base64.b64decode(b64)))

# -------------------- State kh·ªüi t·∫°o --------------------
if "profile" not in st.session_state:
    st.session_state.profile = {"name": "B·∫°n", "avatar_b64": None}

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system",
         "content": "B·∫°n l√† tr·ª£ l√Ω h·ªØu √≠ch, tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† ƒë√∫ng tr·ªçng t√¢m."}
    ]

# -------------------- Sidebar: C√†i ƒë·∫∑t + H·ªì s∆° --------------------
with st.sidebar:
    st.header("C√†i ƒë·∫∑t")
    model = st.selectbox("Model", ["gpt-4o-mini", "gpt-4o", "o4-mini"], index=0)
    temperature = st.slider("Nhi·ªát ƒë·ªô", 0.0, 1.0, 0.3, 0.1)
    max_tokens = st.slider("Max tokens (ƒë√°p √°n)", 64, 2048, 512, 64)
    st.markdown("---")

    st.subheader("üßë‚Äçüé® H·ªì s∆°")
    name = st.text_input("T√™n hi·ªÉn th·ªã", value=st.session_state.profile["name"])

    c1, c2 = st.columns(2)
    with c1:
        up = st.file_uploader("T·∫£i ·∫£nh ƒë·∫°i di·ªán", type=["png", "jpg", "jpeg"])
    with c2:
        cam = st.camera_input("Ch·ª•p ·∫£nh")

    avatar_img = None
    if cam is not None:
        avatar_img = Image.open(cam)
    elif up is not None:
        avatar_img = Image.open(up)

    st.session_state.profile["name"] = name
    if avatar_img is not None:
        st.session_state.profile["avatar_b64"] = _img_to_b64(avatar_img.convert("RGBA"))

    st.caption("Xem tr∆∞·ªõc")
    pc1, pc2 = st.columns([1, 2])
    with pc1:
        if st.session_state.profile["avatar_b64"]:
            st.image(_b64_to_img(st.session_state.profile["avatar_b64"]), width=80, clamp=True)
        else:
            st.image("https://placehold.co/80x80?text=üôÇ", width=80, clamp=True)
    with pc2:
        st.markdown(f"**{st.session_state.profile['name']}**")

    if st.session_state.profile["avatar_b64"]:
        if st.button("X√≥a ·∫£nh ƒë·∫°i di·ªán"):
            st.session_state.profile["avatar_b64"] = None
            st.rerun()

# -------------------- Ti√™u ƒë·ªÅ --------------------
header_l, header_r = st.columns([1, 6])
with header_l:
    if st.session_state.profile["avatar_b64"]:
        st.image(_b64_to_img(st.session_state.profile["avatar_b64"]), width=60)
    else:
        st.image("https://placehold.co/60x60?text=üôÇ", width=60)
with header_r:
    st.title("üí¨ Chat v·ªõi OpenAI (s·∫£n ph·∫©m c·ªßa DuyKh√°nh, QuocHo√†ng, B√© H∆∞uNh√¢n)")
    st.caption(f"Model m·∫∑c ƒë·ªãnh: gpt-4o-mini ‚Ä¢ Xin ch√†o, **{st.session_state.profile['name']}** üëã")

# -------------------- Hi·ªÉn th·ªã l·ªãch s·ª≠ --------------------
for m in st.session_state.messages:
    if m["role"] == "system":
        continue
    with st.chat_message(m["role"]):
        # N·∫øu c√≥ tr∆∞·ªùng 'image_b64' trong message (do ng∆∞·ªùi d√πng g·ª≠i k√®m ·∫£nh), hi·ªÉn th·ªã ·∫£nh
        if isinstance(m.get("content"), dict) and m["content"].get("text") is not None:
            st.markdown(m["content"]["text"])
            if m["content"].get("image_b64"):
                st.image(_b64_to_img(m["content"]["image_b64"]), caption="·∫¢nh ƒë√≠nh k√®m", use_column_width=True)
        else:
            st.markdown(m["content"])

# -------------------- Khu v·ª±c nh·∫≠p + ƒë√≠nh k√®m ·∫£nh --------------------
st.markdown("### G·ª≠i c√¢u h·ªèi")
attach_img_cam = st.camera_input("üì∏ Ch·ª•p ·∫£nh ƒë√≠nh k√®m (tu·ª≥ ch·ªçn)")
attach_img_file = st.file_uploader("Ho·∫∑c t·∫£i ·∫£nh t·ª´ m√°y", type=["png", "jpg", "jpeg"], key="file_attach")

attached_b64 = None
mime_type = None
if attach_img_cam is not None:
    attached_b64 = base64.b64encode(attach_img_cam.getvalue()).decode("utf-8")
    mime_type = "image/png"
elif attach_img_file is not None:
    attached_b64 = base64.b64encode(attach_img_file.getvalue()).decode("utf-8")
    # ƒëo√°n mime
    mime_type = "image/png" if attach_img_file.type in (None, "", "application/octet-stream") else attach_img_file.type

prompt = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n‚Ä¶")

# -------------------- G·ª≠i y√™u c·∫ßu --------------------
if prompt:
    # L∆∞u b·∫£n ghi ng∆∞·ªùi d√πng (k√®m ·∫£nh n·∫øu c√≥) ƒë·ªÉ hi·ªÉn th·ªã l·∫°i
    if attached_b64:
        user_content = {"text": prompt, "image_b64": attached_b64}
        st.session_state.messages.append({"role": "user", "content": user_content})
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)
        if attached_b64:
            st.image(_b64_to_img(attached_b64), caption="·∫¢nh ƒë√≠nh k√®m", use_column_width=True)

    # --------- T·∫°o system prompt c√° nh√¢n ho√° ---------
    system_prompt = f"""
    B·∫°n l√† tr·ª£ l√Ω th√¢n thi·ªán v√† h·ªØu √≠ch. Khi ph√π h·ª£p, x∆∞ng h√¥ v·ªõi ng∆∞·ªùi d√πng b·∫±ng t√™n: {st.session_state.profile['name']}.
    N·∫øu c√≥ ·∫£nh ƒë√≠nh k√®m, h√£y m√¥ t·∫£ n·ªôi dung v√† h·ªó tr·ª£ theo y√™u c·∫ßu. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ƒë√∫ng tr·ªçng t√¢m.
    """

    with st.chat_message("assistant"):
        try:
            if attached_b64:
                # ===== D√πng Responses API khi c√≥ ·∫£nh =====
                content_blocks = [
                    {"type": "text", "text": f"{st.session_state.profile['name']}: {prompt}"},
                    {"type": "input_image", "image_data": attached_b64, "mime_type": mime_type or "image/png"},
                ]
                resp = client.responses.create(
                    model=model,  # gpt-4o-mini/4o h·ªó tr·ª£ ƒëa ph∆∞∆°ng th·ª©c
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system_prompt}]},
                        {"role": "user", "content": content_blocks},
                    ],
                    temperature=temperature,
                    max_output_tokens=max_tokens,
                )
                answer = resp.output_text
            else:
                # ===== Kh√¥ng c√≥ ·∫£nh ‚Üí d√πng Chat Completions truy·ªÅn th·ªëng =====
                # Duy tr√¨ system prompt ·ªü ƒë·∫ßu
                msgs = [{"role": "system", "content": system_prompt}]
                # Chuy·ªÉn c√°c l·ªãch s·ª≠ c≈© sang d·∫°ng text (b·ªè ph·∫ßn ·∫£nh n·∫øu c√≥)
                for m in st.session_state.messages:
                    if m["role"] == "system":
                        continue
                    if isinstance(m.get("content"), dict):
                        txt = m["content"].get("text", "")
                    else:
                        txt = m.get("content", "")
                    msgs.append({"role": m["role"], "content": txt})

                resp = client.chat.completions.create(
                    model=model,
                    messages=msgs,
                    temperature=temperature,
                    max_tokens=max_tokens,
                )
                answer = resp.choices[0].message.content

            st.markdown(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})

        except Exception as e:
            # Fallback: n·∫øu Responses API ch∆∞a kh·∫£ d·ª•ng, th·ª≠ √©p v·ªÅ Chat Completions ch·ªâ v·ªõi text
            st.warning("Th·ª≠ l·∫°i b·∫±ng ch·∫ø ƒë·ªô vƒÉn b·∫£n do l·ªói khi g·ª≠i ·∫£nh.")
            try:
                msgs = [{"role": "system", "content": system_prompt}]
                msgs += [{"role": "user", "content": prompt}]
                resp = client.chat.completions.create(
                    model=model,
                    messages=msgs,
                    temperature=temperature,
                    max_tokens=max_tokens,
                )
                answer = resp.choices[0].message.content
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e2:
                st.error(f"L·ªói g·ªçi OpenAI API: {e2}")
